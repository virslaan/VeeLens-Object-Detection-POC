<!DOCTYPE html>
<html>
<head>
    <title>VeeLens: Object Detection with TensorFlow.js</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        body {
            background-color: #f8f9fa;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
        }
        #webcam-container {
            position: relative;
            height: 480px;
            width: 640px;
        }
        #webcam {
            position: absolute;
            height: 480px;
            width: 640px;
            z-index: 1;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            height: 480px;
            width: 640px;
            z-index: 2;
            background: repeating-linear-gradient(0deg, transparent, transparent 39px, #000 39px, #000 40px),
                        repeating-linear-gradient(90deg, transparent, transparent 39px, #000 39px, #000 40px);
            background-color: transparent;
        }
        #prediction-list {
            position: absolute;
            top: 500px;
            max-height: 200px;
            overflow-y: auto;
        }
    </style>
</head>
<body>
    <div id="webcam-container">
        <video autoplay id="webcam"></video>
        <canvas id="canvas"></canvas>
    </div>
    <div id="prediction-list"></div>

    <script type="text/javascript">
        const video = document.getElementById('webcam');
        const liveView = document.getElementById('canvas');
        const context = liveView.getContext('2d');
        const predictionList = document.getElementById('prediction-list');

        // Check if webcam access is supported.
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
                video.srcObject = stream;
                video.addEventListener('loadeddata', predictWebcam);
            });
        }

        // Load the model.
        let model = undefined;
        cocoSsd.load().then(loadedModel => {
            model = loadedModel;
        });

        // Predict the frame from webcam.
        function predictWebcam() {
            model.detect(video).then(predictions => {
                // Clear the canvas.
                context.clearRect(0, 0, liveView.width, liveView.height);

                // Draw predictions.
                for (let n = 0; n < predictions.length; n++) {
                    if (predictions[n].score > 0.8) {
                        context.beginPath();
                        context.rect(predictions[n].bbox[0], predictions[n].bbox[1], predictions[n].bbox[2], predictions[n].bbox[3]);
                        context.lineWidth = 2;
                        context.strokeStyle = 'red';
                        context.fillStyle = 'red';
                        context.stroke();
                        context.fillText(predictions[n].class + ' - ' + Math.round(parseFloat(predictions[n].score) * 100) + '%', predictions[n].bbox[0], predictions[n].bbox[1] > 10 ? predictions[n].bbox[1] - 5 : 10);
                        
                        // Log detected object to prediction list.
                        const predictionElement = document.createElement('div');
                        predictionElement.textContent = predictions[n].class + ' - ' + Math.round(parseFloat(predictions[n].score) * 100) + '%';
                        predictionList.appendChild(predictionElement);
                    }
                }

                // Call this function again to keep predicting when the browser is ready.
                window.requestAnimationFrame(predictWebcam);
            });
        }
    </script>
</body>
</html>
